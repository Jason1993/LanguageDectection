{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now processing sl...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now processing sk...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now processing pl...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now processing sv...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now processing da...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now processing el...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now processing lv...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now processing it...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now processing cs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now processing ro...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now processing pt...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now processing hu...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now processing nl...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now processing bg...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now processing de...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now processing fi...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now processing fr...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now processing es...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now processing et...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now processing en...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now processing lt...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import operator\n",
    "import re\n",
    "import codecs\n",
    "import json\n",
    "\n",
    "def getWords(text):\n",
    "    return re.compile('\\w+').findall(text)\n",
    "\n",
    "def buildModel():\n",
    "    '''\n",
    "    This model uses zipf's law to help decide the category of document;\n",
    "    This model contains the most 50 frequent occurance N-grams in each language.\n",
    "    Return: uniGramModel, biGramModel, triGramModel\n",
    "    '''\n",
    "    langList = []\n",
    "    #Jupyter network file path:./Desktop/NLP/txt/\n",
    "    #Need to modify path when run on your own environment.\n",
    "    path = './Desktop/NLP/txt/'\n",
    "    for name in os.listdir(path):\n",
    "        if len(name) == 2:\n",
    "            langList.append(name)\n",
    "    uniGramodel = {}\n",
    "    biGramodel = {}\n",
    "    triGramodel = {}\n",
    "    for lang in langList:\n",
    "        print(\"Now processing \" + lang+\"...\")\n",
    "        uniGramodel[lang] = {}\n",
    "        biGramodel[lang] = {}\n",
    "        triGramodel[lang] = {}\n",
    "        for filename in os.listdir(path+lang+\"/\"):\n",
    "            with codecs.open(path+lang+\"/\"+filename, \"r\", encoding='utf-8', errors='ignore') as fdata:\n",
    "                for line in fdata:\n",
    "                    #print(type(line))\n",
    "                    #print(\"Program is running\")\n",
    "                    if line[0] == '<':\n",
    "                        continue\n",
    "                    phrases = line.split('.')\n",
    "                    for phra in phrases:\n",
    "                        wordList = getWords(phra)\n",
    "                        for i,word in enumerate(wordList):\n",
    "                            word = word.strip()\n",
    "                            if i == 0:\n",
    "                                biGram = (\"\",word)\n",
    "                                if i+1 < len(wordList):\n",
    "                                    triGram = (\"\",word,wordList[i+1].strip())\n",
    "                                else:\n",
    "                                    triGram = None\n",
    "                            elif i == len(wordList)-1:\n",
    "                                biGram = (word,\"\")\n",
    "                                triGram = (wordList[i-1].strip(),word,\"\")\n",
    "                            else:\n",
    "                                biGram = (word,wordList[i+1])\n",
    "                                if i+2 < len(wordList):\n",
    "                                    triGram = (wordList[i],wordList[i+1],wordList[i+2])\n",
    "                                else:\n",
    "                                    triGram = None\n",
    "                            if word not in uniGramodel[lang]:\n",
    "                                uniGramodel[lang][word] = 1\n",
    "                            else:\n",
    "                                uniGramodel[lang][word] += 1\n",
    "                            if biGram not in biGramodel[lang]:\n",
    "                                biGramodel[lang][biGram] = 1\n",
    "                            else:\n",
    "                                biGramodel[lang][biGram] += 1\n",
    "                            if triGram != None:\n",
    "                                if triGram not in triGramodel[lang]:\n",
    "                                    triGramodel[lang][triGram] = 1\n",
    "                                else:\n",
    "                                    triGramodel[lang][triGram] += 1\n",
    "    uniGramList = {}\n",
    "    biGramList = {}\n",
    "    triGramList = {}\n",
    "    for lang in langList:\n",
    "        uniGramodel[lang] = sorted(uniGramodel[lang].items(), key = operator.itemgetter(1), reverse = True)\n",
    "        biGramodel[lang] = sorted(biGramodel[lang].items(), key = operator.itemgetter(1), reverse = True)\n",
    "        triGramodel[lang] = sorted(triGramodel[lang].items(), key = operator.itemgetter(1), reverse = True)\n",
    "        uniGramList[lang] = []\n",
    "        biGramList[lang] = []\n",
    "        triGramList[lang] = []\n",
    "        for i in range(50):\n",
    "            uniGramList[lang].append(uniGramodel[lang][i][0])\n",
    "            biGramList[lang].append(biGramodel[lang][i][0])\n",
    "            triGramList[lang].append(triGramodel[lang][i][0])\n",
    "    print(\"N-Gram Model building finshied\")\n",
    "\n",
    "    return uniGramList,biGramList,triGramList,langList\n",
    "\n",
    "#uni,bi,tri = buildModel()\n",
    "def getLabel(uniGramList, biGramList, triGramList, document,langList):\n",
    "    '''\n",
    "    This function is to calculate the distance from document to all possible languages.\n",
    "    The document will be labeled as the shortest distance language.\n",
    "    Params:\n",
    "    uniGramList, biGramList, triGramList, document\n",
    "    Return:\n",
    "    document language label\n",
    "    '''\n",
    "    phrases = document.split('.')\n",
    "    docUni = {}\n",
    "    docBi = {}\n",
    "    docTri = {}\n",
    "    for phra in phrases:\n",
    "        wordList = getWords(phra)\n",
    "        for i,word in enumerate(wordList):\n",
    "            word = word.strip()\n",
    "            if i == 0:\n",
    "                biGram = (\"\", word)\n",
    "                if i + 1 < len(wordList):\n",
    "                    triGram = (\"\", word, wordList[i + 1].strip())\n",
    "                else:\n",
    "                    triGram = None\n",
    "            elif i == len(wordList) - 1:\n",
    "                biGram = (word, \"\")\n",
    "                triGram = (wordList[i - 1].strip(), word, \"\")\n",
    "            else:\n",
    "                biGram = (word, wordList[i + 1])\n",
    "                if i + 2 < len(wordList):\n",
    "                    triGram = (wordList[i], wordList[i + 1], wordList[i + 2])\n",
    "                else:\n",
    "                    triGram = None\n",
    "            if word not in docUni:\n",
    "                docUni[word] = 1\n",
    "            else:\n",
    "                docUni[word] += 1\n",
    "            if biGram not in docBi:\n",
    "                docBi[biGram] = 1\n",
    "            else:\n",
    "                docBi[biGram] += 1\n",
    "            if triGram != None:\n",
    "                if triGram not in docTri:\n",
    "                    docTri[triGram] = 1\n",
    "                else:\n",
    "                    docTri[triGram] += 1\n",
    "    docUni = sorted(docUni.items(), key = operator.itemgetter(1), reverse = True)\n",
    "    docBi = sorted(docBi.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    docTri = sorted(docTri.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    disUni = {}\n",
    "    disBi = {}\n",
    "    disTri = {}\n",
    "    score = {}\n",
    "    for lang in langList:\n",
    "        disUni[lang] = 0\n",
    "        disBi[lang] = 0\n",
    "        disTri[lang] = 0\n",
    "        for i in range(len(docUni)):\n",
    "            if docUni[i][0] in uniGramList[lang]:\n",
    "                disUni[lang] += abs(uniGramList[lang].index(docUni[i][0])-i)\n",
    "            else:\n",
    "                disUni[lang] += 50\n",
    "        for i in range(len(docBi)):\n",
    "            if docBi[i][0] in biGramList[lang]:\n",
    "                disBi[lang] += abs(biGramList[lang].index(docBi[i][0])-i)\n",
    "            else:\n",
    "                disBi[lang] += 50\n",
    "        for i in range(len(docTri)):\n",
    "            if docTri[i][0] in triGramList[lang]:\n",
    "                disTri[lang] += abs(triGramList[lang].index(docTri[i][0])-i)\n",
    "            else:\n",
    "                disTri[lang] += 50\n",
    "        score[lang] = disUni[lang]+disBi[lang]+disTri[lang]\n",
    "    score = sorted(score.items(), key = operator.itemgetter(1))\n",
    "    return score[0][0]\n",
    "\n",
    "\n",
    "def main():\n",
    "    uni,bi,tri,lang = buildModel()\n",
    "    correct = 0\n",
    "    count = 0\n",
    "    with codecs.open(\"./PycharmProjects/LanguageCat/europarl.test\", \"r\", encoding='utf-8', errors='ignore') as fdata:\n",
    "        for i,line in enumerate(fdata):\n",
    "            doc = line[3:]\n",
    "            label = getLabel(uni,bi,tri,doc,lang)\n",
    "            if label == line[0:2]:\n",
    "                correct += 1\n",
    "            count += 1\n",
    "    print(\"The accuracy is: \"+str(correct/count))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}